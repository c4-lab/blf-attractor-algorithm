{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1766f59-4122-4739-b286-09dd85cca48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "path_to_data = \"/home/jli159/blf/trace_cc_with_final_basins.csv\"\n",
    "trace = pd.read_csv(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11992845-f09d-46cb-a9a2-382c3eb81a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x', 'y', 'dt', 'u_id', 'clust_labels', 'botscore', 'basin',\n",
       "       'x_grid_float', 'y_grid_float', 'x_grid', 'y_grid', 'mu_dx', 'mu_dy',\n",
       "       'var_dx', 'var_dy', 'speed', 'basin_id', 'dist_to_edge',\n",
       "       'norm_dist_to_edge', 'dist_to_center', 'basin_avg_speed',\n",
       "       'basin_convergence', 'basin_size', 'prev_basin', 'basin_change',\n",
       "       'transition_confidence', 'basin_belief', 'cumulative_basin_belief',\n",
       "       'time_in_basin', 'delta_x', 'delta_y', 'movement_magnitude',\n",
       "       'time_diff', 'user_speed', 'user_basin_entropy', 'user_basin_changes',\n",
       "       'user_total_moves', 'user_change_rate', 'user_avg_speed',\n",
       "       'user_avg_movement', 'user_stability_index', 'final_basin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff10cd27-c0ba-4746-9c07-112ff5e31f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = trace[['u_id', 'dt', 'x', 'y', 'mu_dx', 'mu_dy', 'final_basin']]\n",
    "trace['dt'] = pd.to_datetime(trace['dt'])\n",
    "trace = trace.sort_values(['u_id', 'dt'])\n",
    "\n",
    "# Calculate prev_x and prev_y\n",
    "trace[['prev_x', 'prev_y']] = trace.groupby('u_id')[['x', 'y']].shift(1)\n",
    "\n",
    "# For the first entry per user, where prev_x/prev_y is NaN, set it equal to x/y\n",
    "mask_first = trace['prev_x'].isna()\n",
    "trace.loc[mask_first, 'prev_x'] = trace.loc[mask_first, 'x']\n",
    "trace.loc[mask_first, 'prev_y'] = trace.loc[mask_first, 'y']\n",
    "\n",
    "# Now calculate dx/dy: will be zero for first entry per user\n",
    "trace['dx'] = trace['x'] - trace['prev_x']\n",
    "trace['dy'] = trace['y'] - trace['prev_y']\n",
    "\n",
    "# --- Calculate cosine similarity for each movement ---\n",
    "def cosine_similarity(row):\n",
    "    a = np.array([row['dx'], row['dy']])\n",
    "    b = np.array([row['mu_dx'], row['mu_dy']])\n",
    "    if np.linalg.norm(a) == 0 or np.linalg.norm(b) == 0:\n",
    "        return np.nan  # Or 0, if you want to treat zero movement as \"neutral\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "trace['cosine_sim'] = trace.apply(cosine_similarity, axis=1)\n",
    "# Aggregate by user: take mean cosine similarity (or other stats if needed)\n",
    "trace['cosine_sim'] = trace['cosine_sim'].fillna(0)\n",
    "\n",
    "# For each user, check if their final_basin changes\n",
    "def user_basin_change(x):\n",
    "    return int(x['final_basin'].nunique() > 1)\n",
    "\n",
    "# Map result to all rows for that user\n",
    "trace['belief_change'] = trace.groupby('u_id')['final_basin'].transform(lambda x: int(x.nunique() > 1))\n",
    "# Convert timestamp to datetime\n",
    "trace['dt'] = pd.to_datetime(trace['dt'])\n",
    "# Compute the time difference in days with granularity\n",
    "trace['time_diff'] = trace.groupby('u_id')['dt'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / (24 * 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a8b87b0-505e-4dbf-ae4c-b956b592a591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>dt</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>mu_dx</th>\n",
       "      <th>mu_dy</th>\n",
       "      <th>final_basin</th>\n",
       "      <th>prev_x</th>\n",
       "      <th>prev_y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>belief_change</th>\n",
       "      <th>time_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12428</td>\n",
       "      <td>2020-09-21 17:07:48+00:00</td>\n",
       "      <td>22.076456</td>\n",
       "      <td>-4.707787</td>\n",
       "      <td>2.675405</td>\n",
       "      <td>6.800396</td>\n",
       "      <td>0</td>\n",
       "      <td>22.076456</td>\n",
       "      <td>-4.707787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12428</td>\n",
       "      <td>2020-10-05 13:11:46+00:00</td>\n",
       "      <td>21.852156</td>\n",
       "      <td>-5.451804</td>\n",
       "      <td>4.196840</td>\n",
       "      <td>2.252347</td>\n",
       "      <td>0</td>\n",
       "      <td>22.076456</td>\n",
       "      <td>-4.707787</td>\n",
       "      <td>-0.224300</td>\n",
       "      <td>-0.744017</td>\n",
       "      <td>-0.707082</td>\n",
       "      <td>0</td>\n",
       "      <td>13.836088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12428</td>\n",
       "      <td>2020-10-06 01:30:51+00:00</td>\n",
       "      <td>22.517124</td>\n",
       "      <td>-4.323751</td>\n",
       "      <td>1.484263</td>\n",
       "      <td>4.452345</td>\n",
       "      <td>0</td>\n",
       "      <td>21.852156</td>\n",
       "      <td>-5.451804</td>\n",
       "      <td>0.664968</td>\n",
       "      <td>1.128053</td>\n",
       "      <td>0.977849</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12428</td>\n",
       "      <td>2020-10-06 01:36:42+00:00</td>\n",
       "      <td>23.640362</td>\n",
       "      <td>-2.489461</td>\n",
       "      <td>-0.555071</td>\n",
       "      <td>-0.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>22.517124</td>\n",
       "      <td>-4.323751</td>\n",
       "      <td>1.123238</td>\n",
       "      <td>1.834290</td>\n",
       "      <td>-0.588151</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29283</td>\n",
       "      <td>2020-07-26 15:00:07+00:00</td>\n",
       "      <td>23.296371</td>\n",
       "      <td>-4.816743</td>\n",
       "      <td>2.255973</td>\n",
       "      <td>2.391535</td>\n",
       "      <td>0</td>\n",
       "      <td>23.296371</td>\n",
       "      <td>-4.816743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29283</td>\n",
       "      <td>2020-08-08 22:40:35+00:00</td>\n",
       "      <td>26.746895</td>\n",
       "      <td>-3.141624</td>\n",
       "      <td>-4.145869</td>\n",
       "      <td>1.293410</td>\n",
       "      <td>1</td>\n",
       "      <td>23.296371</td>\n",
       "      <td>-4.816743</td>\n",
       "      <td>3.450523</td>\n",
       "      <td>1.675119</td>\n",
       "      <td>-0.728709</td>\n",
       "      <td>1</td>\n",
       "      <td>13.319769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29283</td>\n",
       "      <td>2020-08-11 01:25:22+00:00</td>\n",
       "      <td>27.124683</td>\n",
       "      <td>-2.451145</td>\n",
       "      <td>-2.292868</td>\n",
       "      <td>-1.383628</td>\n",
       "      <td>2</td>\n",
       "      <td>26.746895</td>\n",
       "      <td>-3.141624</td>\n",
       "      <td>0.377789</td>\n",
       "      <td>0.690480</td>\n",
       "      <td>-0.864219</td>\n",
       "      <td>1</td>\n",
       "      <td>2.114433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29283</td>\n",
       "      <td>2020-08-14 00:53:27+00:00</td>\n",
       "      <td>26.890812</td>\n",
       "      <td>-3.209466</td>\n",
       "      <td>-5.292282</td>\n",
       "      <td>0.107340</td>\n",
       "      <td>1</td>\n",
       "      <td>27.124683</td>\n",
       "      <td>-2.451145</td>\n",
       "      <td>-0.233871</td>\n",
       "      <td>-0.758322</td>\n",
       "      <td>0.275271</td>\n",
       "      <td>1</td>\n",
       "      <td>2.977836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29283</td>\n",
       "      <td>2020-08-17 13:36:35+00:00</td>\n",
       "      <td>27.144356</td>\n",
       "      <td>-2.407447</td>\n",
       "      <td>-1.966226</td>\n",
       "      <td>-1.316553</td>\n",
       "      <td>2</td>\n",
       "      <td>26.890812</td>\n",
       "      <td>-3.209466</td>\n",
       "      <td>0.253544</td>\n",
       "      <td>0.802019</td>\n",
       "      <td>-0.780965</td>\n",
       "      <td>1</td>\n",
       "      <td>3.529954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29283</td>\n",
       "      <td>2020-08-17 15:53:10+00:00</td>\n",
       "      <td>27.091753</td>\n",
       "      <td>-2.292559</td>\n",
       "      <td>-1.788803</td>\n",
       "      <td>-0.881881</td>\n",
       "      <td>2</td>\n",
       "      <td>27.144356</td>\n",
       "      <td>-2.407447</td>\n",
       "      <td>-0.052603</td>\n",
       "      <td>0.114888</td>\n",
       "      <td>-0.028656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    u_id                        dt          x         y     mu_dx     mu_dy  \\\n",
       "0  12428 2020-09-21 17:07:48+00:00  22.076456 -4.707787  2.675405  6.800396   \n",
       "1  12428 2020-10-05 13:11:46+00:00  21.852156 -5.451804  4.196840  2.252347   \n",
       "2  12428 2020-10-06 01:30:51+00:00  22.517124 -4.323751  1.484263  4.452345   \n",
       "3  12428 2020-10-06 01:36:42+00:00  23.640362 -2.489461 -0.555071 -0.044118   \n",
       "4  29283 2020-07-26 15:00:07+00:00  23.296371 -4.816743  2.255973  2.391535   \n",
       "5  29283 2020-08-08 22:40:35+00:00  26.746895 -3.141624 -4.145869  1.293410   \n",
       "6  29283 2020-08-11 01:25:22+00:00  27.124683 -2.451145 -2.292868 -1.383628   \n",
       "7  29283 2020-08-14 00:53:27+00:00  26.890812 -3.209466 -5.292282  0.107340   \n",
       "8  29283 2020-08-17 13:36:35+00:00  27.144356 -2.407447 -1.966226 -1.316553   \n",
       "9  29283 2020-08-17 15:53:10+00:00  27.091753 -2.292559 -1.788803 -0.881881   \n",
       "\n",
       "   final_basin     prev_x    prev_y        dx        dy  cosine_sim  \\\n",
       "0            0  22.076456 -4.707787  0.000000  0.000000    0.000000   \n",
       "1            0  22.076456 -4.707787 -0.224300 -0.744017   -0.707082   \n",
       "2            0  21.852156 -5.451804  0.664968  1.128053    0.977849   \n",
       "3            0  22.517124 -4.323751  1.123238  1.834290   -0.588151   \n",
       "4            0  23.296371 -4.816743  0.000000  0.000000    0.000000   \n",
       "5            1  23.296371 -4.816743  3.450523  1.675119   -0.728709   \n",
       "6            2  26.746895 -3.141624  0.377789  0.690480   -0.864219   \n",
       "7            1  27.124683 -2.451145 -0.233871 -0.758322    0.275271   \n",
       "8            2  26.890812 -3.209466  0.253544  0.802019   -0.780965   \n",
       "9            2  27.144356 -2.407447 -0.052603  0.114888   -0.028656   \n",
       "\n",
       "   belief_change  time_diff  \n",
       "0              0   0.000000  \n",
       "1              0  13.836088  \n",
       "2              0   0.513252  \n",
       "3              0   0.004063  \n",
       "4              1   0.000000  \n",
       "5              1  13.319769  \n",
       "6              1   2.114433  \n",
       "7              1   2.977836  \n",
       "8              1   3.529954  \n",
       "9              1   0.094850  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf386407-bfe0-4093-affe-473acace0074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_id                0\n",
      "dt                  0\n",
      "x                   0\n",
      "y                   0\n",
      "mu_dx            1867\n",
      "mu_dy            1867\n",
      "final_basin         0\n",
      "prev_x              0\n",
      "prev_y              0\n",
      "dx                  0\n",
      "dy                  0\n",
      "cosine_sim          0\n",
      "belief_change       0\n",
      "time_diff           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(trace.isna().sum())\n",
    "# Shows the number of NaNs for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6d0607e-5ee3-419a-9947-4e077ff7dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace['mu_dx'] = trace['mu_dx'].fillna(0)\n",
    "trace['mu_dy'] = trace['mu_dy'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f14a0f26-f1fe-4669-9eb5-2472af36b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 60,058  |  Unique users: 13,236\n"
     ]
    }
   ],
   "source": [
    "# Posts\n",
    "WINDOW  = 20          # number of statements per sample\n",
    "STRIDE  = 3           # slide by 5 rows ⇒ overlapping windows\n",
    "FEATS   = ['cosine_sim', 'time_diff']   # ← add more features if desired\n",
    "\n",
    "seqs, lengths, labels = [], [], []\n",
    "\n",
    "for uid, sub in trace.groupby('u_id'):\n",
    "    arr = sub[FEATS].to_numpy(dtype=np.float32)\n",
    "    lbl = int(sub['belief_change'].iloc[0])\n",
    "    # cut into [WINDOW]-long chunks; keep a final shorter tail\n",
    "    for start in range(0, len(arr), STRIDE):\n",
    "        chunk = arr[start:start+WINDOW]\n",
    "        if len(chunk)==0:               # shouldn’t happen\n",
    "            continue\n",
    "        seqs.append(torch.tensor(chunk))\n",
    "        lengths.append(len(chunk))\n",
    "        labels.append(lbl)\n",
    "\n",
    "print(f\"Total samples: {len(seqs):,}  |  Unique users: {trace.u_id.nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b0ef2dd-0ec3-4171-be40-bcbdb40b907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day-windows: 126,179  |  Unique users: 13,236\n"
     ]
    }
   ],
   "source": [
    "# Or in days\n",
    "WINDOW = 30      # width of each window  (days)\n",
    "STRIDE = 5       # slide amount          (days)\n",
    "FEATS       = ['cosine_sim', 'time_diff']   # same feature list\n",
    "\n",
    "seqs, lengths, labels = [], [], []\n",
    "\n",
    "for uid, sub in trace.groupby('u_id'):\n",
    "    sub = sub.sort_values('dt')                  # already sorted, but be safe\n",
    "    label = int(sub['belief_change'].iloc[0])    # constant for this user\n",
    "    \n",
    "    # iterate over the user’s timeline with a rolling [start, start+WINDOW]\n",
    "    win_start = sub['dt'].min()\n",
    "    last_time = sub['dt'].max()\n",
    "    \n",
    "    while win_start <= last_time:\n",
    "        win_end = win_start + pd.Timedelta(days=WINDOW)\n",
    "        mask    = (sub['dt'] >= win_start) & (sub['dt'] <  win_end)\n",
    "        chunk_df = sub.loc[mask, FEATS]\n",
    "        \n",
    "        if chunk_df.empty:                # no statements in this slice → skip\n",
    "            win_start += pd.Timedelta(days=STRIDE)\n",
    "            continue\n",
    "        \n",
    "        seqs.append(torch.tensor(chunk_df.to_numpy(dtype=np.float32)))\n",
    "        lengths.append(len(chunk_df))\n",
    "        labels.append(label)\n",
    "        \n",
    "        win_start += pd.Timedelta(days=STRIDE)\n",
    "\n",
    "print(f\"Day-windows: {len(seqs):,}  |  Unique users: {trace.u_id.nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f38badc3-3ec2-4321-bd78-a29a99a90cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeliefWindowDataset(Dataset):\n",
    "    def __init__(self, sequences, lengths, labels):\n",
    "        self.sequences = sequences\n",
    "        self.lengths   = lengths\n",
    "        self.labels    = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.lengths[idx], self.labels[idx]\n",
    "\n",
    "def collate(batch):\n",
    "    seqs, lens, lbls = zip(*batch)\n",
    "    # pad to longest in mini-batch (NOT to WINDOW necessarily)\n",
    "    padded = pad_sequence(seqs, batch_first=True)          # [B, Lmax, F]\n",
    "    lens   = torch.tensor(lens)\n",
    "    lbls   = torch.tensor(lbls, dtype=torch.float32)\n",
    "    return padded, lens, lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a58a9b9-a57b-4345-bad3-b48b2576fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1  collect a set of windows per user\n",
    "by_user = {}\n",
    "for (seq, ln, lbl), uid in zip(zip(seqs, lengths, labels), trace.groupby('u_id').groups):\n",
    "    by_user.setdefault(uid, []).append((seq, ln, lbl))\n",
    "\n",
    "uids = np.array(list(by_user.keys()))\n",
    "train_uid, temp_uid = train_test_split(uids, test_size=0.3, random_state=SEED, stratify=[\n",
    "                                       by_user[uid][0][2] for uid in uids])\n",
    "val_uid,  test_uid  = train_test_split(temp_uid, test_size=0.5, random_state=SEED, stratify=[\n",
    "                                       by_user[uid][0][2] for uid in temp_uid])\n",
    "\n",
    "def rebuild(uid_subset):\n",
    "    s,l,y = [],[],[]\n",
    "    for uid in uid_subset:\n",
    "        for seq, ln, lbl in by_user[uid]:\n",
    "            s.append(seq); l.append(ln); y.append(lbl)\n",
    "    return BeliefWindowDataset(s,l,y)\n",
    "\n",
    "train_ds, val_ds, test_ds = map(rebuild, [train_uid,val_uid,test_uid])\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True,  collate_fn=collate)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=128, shuffle=False, collate_fn=collate)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=128, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9a1ada9-cb42-4a71-a50e-967ead8cc686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 0.5922 | val AUROC 0.7086\n",
      "Epoch 02 | train loss 0.5658 | val AUROC 0.7101\n",
      "Epoch 03 | train loss 0.5632 | val AUROC 0.7281\n",
      "Epoch 04 | train loss 0.5580 | val AUROC 0.7308\n",
      "Epoch 05 | train loss 0.5517 | val AUROC 0.7357\n",
      "Epoch 06 | train loss 0.5340 | val AUROC 0.7561\n",
      "Epoch 07 | train loss 0.5247 | val AUROC 0.7638\n",
      "Epoch 08 | train loss 0.5221 | val AUROC 0.7633\n",
      "Epoch 09 | train loss 0.5155 | val AUROC 0.7589\n",
      "Epoch 10 | train loss 0.5170 | val AUROC 0.7561\n",
      "Epoch 11 | train loss 0.5124 | val AUROC 0.7424\n",
      "Epoch 12 | train loss 0.5195 | val AUROC 0.7638\n",
      "→ early-stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.756     0.336     0.465       589\n",
      "         1.0      0.773     0.954     0.854      1397\n",
      "\n",
      "    accuracy                          0.771      1986\n",
      "   macro avg      0.764     0.645     0.660      1986\n",
      "weighted avg      0.768     0.771     0.739      1986\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 198  391]\n",
      " [  64 1333]]\n",
      "Test AUROC: 0.7398\n"
     ]
    }
   ],
   "source": [
    "class BeliefLSTM(nn.Module):\n",
    "    def __init__(self, in_dims, hid=64, layers=2, bidir=True, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(in_dims, hid, num_layers=layers, \n",
    "                            batch_first=True, bidirectional=bidir,\n",
    "                            dropout=drop if layers>1 else 0.0)\n",
    "        out_dim = hid * (2 if bidir else 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(out_dim),\n",
    "            nn.Linear(out_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lens):\n",
    "        # x: [B, L, F], lens: [B]\n",
    "        packed = pack_padded_sequence(x, lens.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, _) = self.lstm(packed)      # h_n: [layers*dir, B, hid]\n",
    "        # concat final fw + bw if bidirectional\n",
    "        if self.lstm.bidirectional:\n",
    "            h_last = torch.cat((h_n[-2], h_n[-1]), dim=-1)\n",
    "        else:\n",
    "            h_last = h_n[-1]\n",
    "        logits = self.classifier(h_last).squeeze(-1)        # [B]\n",
    "        return logits\n",
    "        \n",
    "\n",
    "model = BeliefLSTM(in_dims=len(FEATS)).to(DEVICE)\n",
    "opt    = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn= nn.BCEWithLogitsLoss()\n",
    "\n",
    "BEST_AUROC, patience, PATIENCE = 0.0, 0, 5\n",
    "for epoch in range(1, 51):      # max 50 epochs\n",
    "    # 6.1  Train\n",
    "    model.train(); tot_loss = 0\n",
    "    for xb, lens, yb in train_dl:\n",
    "        xb, lens, yb = xb.to(DEVICE), lens.to(DEVICE), yb.to(DEVICE)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logits = model(xb, lens)\n",
    "        loss   = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tot_loss += loss.item()*len(yb)\n",
    "    train_loss = tot_loss/len(train_ds)\n",
    "\n",
    "    # 6.2  Validation\n",
    "    model.eval(); all_logits, all_y = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, lens, yb in val_dl:\n",
    "            logits = model(xb.to(DEVICE), lens.to(DEVICE))\n",
    "            all_logits.append(torch.sigmoid(logits).cpu())\n",
    "            all_y.append(yb)\n",
    "    probs = torch.cat(all_logits).numpy()\n",
    "    ys    = torch.cat(all_y).numpy()\n",
    "    auroc = roc_auc_score(ys, probs)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train loss {train_loss:.4f} | val AUROC {auroc:.4f}\")\n",
    "\n",
    "    # early stopping\n",
    "    if auroc > BEST_AUROC + 1e-4:       # significant improvement\n",
    "        BEST_AUROC, patience = auroc, 0\n",
    "        torch.save(model.state_dict(), \"best_lstm.pt\")\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= PATIENCE:\n",
    "            print(\"→ early-stopping\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_lstm.pt\"))\n",
    "model.eval(); all_logits, all_y = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, lens, yb in test_dl:\n",
    "        logits = model(xb.to(DEVICE), lens.to(DEVICE))\n",
    "        all_logits.append(torch.sigmoid(logits).cpu())\n",
    "        all_y.append(yb)\n",
    "\n",
    "probs = torch.cat(all_logits).numpy()\n",
    "ys    = torch.cat(all_y).numpy()\n",
    "yhat  = (probs >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(ys, yhat, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(ys, yhat))\n",
    "print(\"Test AUROC:\", roc_auc_score(ys, probs).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53db7a-029e-4712-813f-5707dafab500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f55b2-f2c8-4bdb-8ab0-ff7ddc50a959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56a0e3-fc4b-41da-875c-3cfaeec64e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacey-kernel",
   "language": "python",
   "name": "spacey-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
